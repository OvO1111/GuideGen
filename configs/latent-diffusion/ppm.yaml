model:
  base_learning_rate: 1.e-5
  train_target: ldm.models.diffusion.ppm.ProjectionDiffusion2D
  test_target: inference.models.InferLatentDiffusion
  params:
    linear_start: 0.0015
    linear_end: 0.0195
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    loss_type: l1
    # first_stage_key: image
    first_stage_key: o
    label_key: index_raw
    cond_stage_key: index
    conditioning_key: crossattn
    image_size: [256, 256]  # after first-stage encoding, infer size
    channels: 8            # after first-stage encoding
    monitor: val/loss_simple
    cond_stage_trainable: true
    use_different_timesteps_per_batch: false
    use_projected_noise: false
    batch_size: 64

    unet_config:
      target: ldm.modules.diffusionmodules.openaimodel.UNetModel
      params:
        in_channels: 8
        out_channels: 8
        model_channels: 96
        attention_resolutions: [8, 16, 32]
        num_res_blocks: 2
        channel_mult: [1, 1, 2, 2, 4, 4]
        num_head_channels: 64
        use_checkpoint: true  # always use ckpt
        dims: 2
        use_spatial_transformer: true
        context_dim: 16

    first_stage_config:
      target: ldm.modules.encoders.modules.IdentityFirstStage

    cond_stage_config:
      target: ldm.modules.encoders.modules.CosineAngleEmbedder
      params:
        d_embed: 16
    
    normalizer_config:
      target: ldm.data.make_dataset.from_latents.ProjectionNorm
      params:
        pm: 0.5e5
        pM: 3.5e5
        om: -1
        oM: 1
          
data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 1
    num_workers: 4
    wrap: False
    common:
      target: ldm.data.make_dataset.from_latents.LatentsDataset
      params:
        data_dir: /hot_data/dlr/datasets/synthetic/projs_set0701
    train:
      params:
        split: train
    validation:
      params:
        split: val
        max_size: 10
    # train:
    #   target: ldm.data.base.MSDDataset
    #   params:
    #     split: train
    #     output_size: [256, 256, 256]
    #     base_dir: ['/home/dlr/data/datasets/CT-RATE']
    #     transforms:
    #       torchio.CropOrPad:
    #         only_crop: true
    #         target_shape: [256, 1024, 1024]
    #       torchio.Resize:
    #         target_shape: [256, 256, 256]
    #         image_interpolation: linear
    #     # max_size: 5
    # validation:
    #   target: ldm.data.base.MSDDataset
    #   params:
    #     split: val
    #     output_size: [256, 256, 256]
    #     base_dir: ['/home/dlr/data/datasets/CT-RATE']
    #     transforms:
    #       torchio.CropOrPad:
    #         only_crop: true
    #         target_shape: [256, 512, 512]
    #       torchio.Resize:
    #         target_shape: [256, 256, 256]
    #         image_interpolation: linear
    # test:
    #   target: ldm.data.make_dataset.from_latents.LatentsDataset
    #   params:
    #     split: test

lightning:
  callbacks:
    image_logger:
      target: main.ImageLogger
      params:
        train_batch_frequency: 100
        val_batch_frequency: 1
        max_images: 10
        log_images_kwargs: 
          ddim_steps: 50
        logger:
          inputs:
            target: image_rescale
          samples:
            target: image_rescale
          fbp:
            target: image_rescale

  trainer:
    benchmark: true
    max_epochs: 1000
    replace_sampler_ddp: true
    limit_test_batches: 500